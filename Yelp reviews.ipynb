{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "# import textacy\n",
    "# from textacy.io.json import read_json\n",
    "import spacy\n",
    "import random\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "# Note that GCC doesn't really help...\n",
    "# Try this?\n",
    "# CPPFLAGS=\"-std=c++98\" pip install cld2-cffi\n",
    "\n",
    "# This only really gets used to create the dataset. You _dont_ have to install this if you don't want to.\n",
    "\n",
    "# def doc_stream():\n",
    "#     c = 0\n",
    "#     with open('./yelp.json') as jfile:\n",
    "#         for obj in json.load(jfile):\n",
    "#             if c >= 10000:\n",
    "#                 break\n",
    "#             if obj['stars'] != [] and random.randint(0, 10) == 0:\n",
    "#                 c += 1\n",
    "#                 print('.', end='')\n",
    "#                 yield textacy.Doc(obj['review'][0], lang='en', metadata={'stars': obj['stars'], 'restaurant': obj['restaurant']})\n",
    "                \n",
    "# corpus = textacy.Corpus('en', docs=doc_stream())\n",
    "\n",
    "# corpus\n",
    "\n",
    "# vectorizer = textacy.Vectorizer(norm='l2', apply_idf=True, idf_type='smooth', min_df=5, max_df=0.95)\n",
    "# doc_term_matrix = vectorizer.fit_transform((doc.to_terms_list(ngrams=1, named_entities=True, as_strings=True) for doc in corpus))\n",
    "# \n",
    "\n",
    "# scipy.sparse.save_npz('./corpus.npz', doc_term_matrix)\n",
    "# \n",
    "\n",
    "# y = np.array([c.metadata['stars'] for c in corpus])\n",
    "\n",
    "# np.save('./ratings.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.load('./ratings.npy')\n",
    "doc_term_matrix = scipy.sparse.load_npz('./corpus.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(doc_term_matrix, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier GaussianNB(priors=None)\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.17      0.47      0.25       194\n",
      "          2       0.09      0.22      0.13       156\n",
      "          3       0.14      0.16      0.15       287\n",
      "          4       0.34      0.23      0.27       577\n",
      "          5       0.51      0.24      0.33       786\n",
      "\n",
      "avg / total       0.34      0.25      0.26      2000\n",
      "\n",
      "------------------------------\n",
      "Classifier RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.45      0.36      0.40       194\n",
      "          2       0.34      0.13      0.19       156\n",
      "          3       0.31      0.13      0.18       287\n",
      "          4       0.36      0.38      0.37       577\n",
      "          5       0.52      0.69      0.59       786\n",
      "\n",
      "avg / total       0.42      0.45      0.42      2000\n",
      "\n",
      "------------------------------\n",
      "Classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.00      0.00      0.00       194\n",
      "          2       0.00      0.00      0.00       156\n",
      "          3       0.00      0.00      0.00       287\n",
      "          4       0.00      0.00      0.00       577\n",
      "          5       0.39      1.00      0.56       786\n",
      "\n",
      "avg / total       0.15      0.39      0.22      2000\n",
      "\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hexgnu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.46      0.53       194\n",
      "          2       0.36      0.17      0.23       156\n",
      "          3       0.35      0.23      0.28       287\n",
      "          4       0.41      0.44      0.42       577\n",
      "          5       0.59      0.74      0.66       786\n",
      "\n",
      "avg / total       0.49      0.51      0.49      2000\n",
      "\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hexgnu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.48      0.53       194\n",
      "          2       0.39      0.13      0.20       156\n",
      "          3       0.40      0.12      0.18       287\n",
      "          4       0.42      0.29      0.34       577\n",
      "          5       0.52      0.86      0.64       786\n",
      "\n",
      "avg / total       0.47      0.49      0.45      2000\n",
      "\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Classifications\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "classifiers = [GaussianNB(),\n",
    "               KNeighborsClassifier(n_neighbors=3), # This is slow as molasses\n",
    "               RandomForestClassifier(random_state=42),\n",
    "               SVC(),\n",
    "               SVC(kernel='linear'),\n",
    "               SGDClassifier()]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(doc_term_matrix, y, test_size=0.2, random_state=42)\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train.toarray(), y_train)\n",
    "    y_pred = clf.predict(X_test.toarray())\n",
    "    print('Classifier {}'.format(clf))\n",
    "    print('-' * 30)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('-' * 30)\n",
    "\n",
    "# Precision is TP / TP + FP: So how many out of the positives were actually right?\n",
    "# Recall is TP / TP + FN: So how many of the relevant elements were selected to begin with?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: What other classifiers could you use?\n",
    "\n",
    "# Are these any better or worse?\n",
    "\n",
    "# Hint any ensemble classifier usually works really well in practice\n",
    "# AdaBoost\n",
    "# RandomForest with tweaks on it? These usually work very well!\n",
    "# GradientBoost\n",
    "\n",
    "# there is also Xgboost and CatBoost for extra points but you'll have to install something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hexgnu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
      "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
      "       loss='squared_loss', max_iter=None, n_iter=None, penalty='l2',\n",
      "       power_t=0.25, random_state=None, shuffle=True, tol=None, verbose=0,\n",
      "       warm_start=False)\n",
      "------------------------------\n",
      "0.9772048992240506\n",
      "------------------------------\n",
      "Regression Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "------------------------------\n",
      "1.044075625\n",
      "------------------------------\n",
      "Regression LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "------------------------------\n",
      "105477975.95579632\n",
      "------------------------------\n",
      "Regression ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      "------------------------------\n",
      "1.044075625\n",
      "------------------------------\n",
      "Regression Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "------------------------------\n",
      "0.7651750194147371\n",
      "------------------------------\n",
      "Regression SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "------------------------------\n",
      "0.776115453764693\n",
      "------------------------------\n",
      "Regression SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "------------------------------\n",
      "1.0012012859610264\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor, Lasso, LinearRegression, ElasticNet, Ridge, LassoCV, RidgeCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "regressors = [SGDRegressor(), \n",
    "              Lasso(), \n",
    "              LinearRegression(), \n",
    "              ElasticNet(),\n",
    "              Ridge(),\n",
    "              SVR(kernel='linear'),\n",
    "              SVR(kernel='rbf')]\n",
    "\n",
    "def print_results(reg, y_test, y_pred):\n",
    "    print('Regression {}'.format(reg))\n",
    "    print('-' * 30)\n",
    "    print(mean_absolute_error(y_test, y_pred))\n",
    "    print('-' * 30)\n",
    "\n",
    "for reg in regressors:\n",
    "    reg.fit(X_train.toarray(), y_train)\n",
    "    y_pred = reg.predict(X_test.toarray())\n",
    "    print_results(reg, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise what other regressors could you use?\n",
    "\n",
    "# Hint the ensemble regressors again tend to work well in practice\n",
    "# We tried all the big ones tbh\n",
    "\n",
    "# http://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble\n",
    "\n",
    "# AdaBoostRegressor\n",
    "# BaggingRegressor\n",
    "# GradientBoostingRegressor\n",
    "\n",
    "# There is also Xgboost and CatBoost for extra points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hexgnu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 1.2644476720300936e-18 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: [1.640819364318025] MAE: 0.7619208958237843\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f72e49b5240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dlib\n",
    "\n",
    "xes = []\n",
    "yes = []\n",
    "\n",
    "def ridge_regressor(alpha):\n",
    "    reg = Ridge(alpha=alpha)\n",
    "    reg.fit(X_train.toarray(), y_train)\n",
    "    y_pred = reg.predict(X_test.toarray())\n",
    "    yes.append(mean_absolute_error(y_test, y_pred))\n",
    "    xes.append(alpha)\n",
    "    return mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "x, y = dlib.find_min_global(ridge_regressor, [1e-15], [20], 80)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Best Alpha: {} MAE: {}\".format(x, y))\n",
    "\n",
    "pd.DataFrame({'x': xes, 'y': yes}).plot.scatter(x='x', y='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: [0.33092015837141103] MAE: 0.771019835531833\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f729398a128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dlib\n",
    "from sklearn.svm import LinearSVR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is \"bleeding\" edge stuff here \n",
    "# http://blog.dlib.net/2017/12/a-global-optimization-algorithm-worth.html\n",
    "\n",
    "xes = []\n",
    "yes = []\n",
    "\n",
    "def svr_regressor(c):\n",
    "    reg = LinearSVR(C=c)\n",
    "    reg.fit(X_train.toarray(), y_train)\n",
    "    y_pred = reg.predict(X_test.toarray())\n",
    "    yes.append(mean_absolute_error(y_test, y_pred))\n",
    "    xes.append(c)\n",
    "    return mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "x, y = dlib.find_min_global(svr_regressor, [1e-15], [200], 80)\n",
    "\n",
    "print(\"Best C: {} MAE: {}\".format(x, y))\n",
    "\n",
    "pd.DataFrame({'x': xes, 'y': yes}).plot.scatter(x='x', y='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hexgnu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2018-08-01 07:44:47,460:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:44:47,470:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:44:47,709:AutoMLSMBO(1)::viet_ratings] Could not find meta-data directory /home/hexgnu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/autosklearn/metalearning/files/r2_regression_dense\n",
      "[WARNING] [2018-08-01 07:44:49,476:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:44:51,480:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:44:53,483:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:44:55,487:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:44:57,494:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:44:59,510:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:01,516:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:03,520:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:05,525:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:07,531:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:09,542:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:11,546:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:13,553:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:15,559:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:17,563:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:19,571:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:21,578:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:23,587:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:25,606:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:27,613:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:29,633:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:31,656:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:33,674:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:35,689:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:37,704:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:39,728:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:41,735:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:43,748:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:45,761:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:47,771:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:49,790:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:51,797:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:53,802:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:55,807:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:57,819:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:45:59,828:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:46:01,855:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:46:03,875:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:46:05,883:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:46:07,899:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:46:09,911:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:46:11,919:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:46:13,943:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:46:15,951:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:46:17,981:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:46:19,999:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:46:22,022:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:46:24,026:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-08-01 07:46:26,030:EnsembleBuilder(1):viet_ratings] No models better than random - using Dummy Classifier!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hexgnu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.000000, SimpleRegressionPipeline({'categorical_encoding:__choice__': 'one_hot_encoding', 'imputation:strategy': 'median', 'preprocessor:__choice__': 'extra_trees_preproc_for_regression', 'regressor:__choice__': 'ridge_regression', 'rescaling:__choice__': 'none', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False', 'preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse', 'preprocessor:extra_trees_preproc_for_regression:max_depth': 'None', 'preprocessor:extra_trees_preproc_for_regression:max_features': 0.4913357283128178, 'preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None', 'preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 17, 'preprocessor:extra_trees_preproc_for_regression:min_samples_split': 13, 'preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0, 'preprocessor:extra_trees_preproc_for_regression:n_estimators': 100, 'regressor:ridge_regression:alpha': 1.0651486396143917, 'regressor:ridge_regression:fit_intercept': 'True', 'regressor:ridge_regression:tol': 0.00442996035466757, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.02757515384354482},\n",
      "dataset_properties={\n",
      "  'task': 4,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})),\n",
      "]\n",
      "Mean absolute error: 0.9896880868673325\n"
     ]
    }
   ],
   "source": [
    "import autosklearn\n",
    "import autosklearn.regression\n",
    "import sklearn\n",
    "\n",
    "automl = autosklearn.regression.AutoSklearnRegressor(\n",
    "    time_left_for_this_task=120,\n",
    "    per_run_time_limit=30,\n",
    "    tmp_folder='/tmp/autosklearn_regression_example_tmp',\n",
    "    output_folder='/tmp/autosklearn_regression_example_out',\n",
    "    ml_memory_limit=5 * 1024\n",
    ")\n",
    "\n",
    "model = automl.fit(X_train.toarray(), y_train, dataset_name='viet_ratings', feat_type=['numerical'] * X_test.shape[1])\n",
    "\n",
    "print(automl.show_models())\n",
    "y_pred = automl.predict(X_test.toarray())\n",
    "print(\"Mean absolute error:\", sklearn.metrics.mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeRegression(alpha=1.0651486396143917, fit_intercept=True,\n",
       "        random_state=<mtrand.RandomState object at 0x7f01cc1961b0>,\n",
       "        tol=0.00442996035466757)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = automl.get_models_with_weights()[0][1]\n",
    "\n",
    "mod._final_estimator.choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
